{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizehrhardt/recaptcha/blob/main/captcha_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCNqFQfp5lwh",
        "outputId": "d98f2668-ce4b-43ed-cf3e-50e28ea1f12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxRz6RWb5vRh",
        "outputId": "c007f73f-328c-4492-fdd3-6e2886bde576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bicycle   Bus\t Chimney     Hydrant\t  Mountain   Palm    'Traffic Light'\n",
            " Bridge    Car\t Crosswalk   Motorcycle   Other      Stairs\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/MyDrive/captcha/large/train\"\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7P-LBC3515V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "large_labels = ['Bicycle', 'Bridge', 'Bus', 'Car', 'Chimney', 'Crosswalk', 'Hydrant', 'Motorcycle', 'Mountain', 'Other', 'Palm', 'Stairs', 'Traffic Light']\n",
        "small_labels = ['Car', 'Crosswalk', 'Hydrant', 'TrafficLight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0nHBcC2532I"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "image_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "np_data = 'numpy_data/'\n",
        "\n",
        "large_train_path = \"/content/drive/MyDrive/captcha/large/train\"\n",
        "large_test_path = \"/content/drive/MyDrive/captcha/large/val\"\n",
        "\n",
        "small_path = \"/content/drive/MyDrive/captcha/small/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMEp9UGt6Cl7"
      },
      "outputs": [],
      "source": [
        "def save_data(data_dir, file_prefix, labels):\n",
        "    data = [] \n",
        "    if (not os.path.exists(data_dir)):\n",
        "      os.mkdir(data_dir)\n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                #img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
        "                img_path = os.path.join(path, img)\n",
        "                img = keras.preprocessing.image.load_img(img_path, target_size=(image_size, image_size))\n",
        "                img_arr = keras.preprocessing.image.img_to_array(img)\n",
        "                img_arr = img_arr/255.0\n",
        "                #img_arr = cv2.imread(os.path.join(path,img),1)\n",
        "                #resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                #data.append([resized_arr, class_num])\n",
        "                data.append([img_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "        np.save(np_data+file_prefix+label, data)\n",
        "    return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVZBLha76KLi"
      },
      "outputs": [],
      "source": [
        "def get_large_data(data_dir):\n",
        "    data = [] \n",
        "    for label in large_labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = large_labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_path = os.path.join(path, img)\n",
        "                img = keras.preprocessing.image.load_img(img_path, target_size=(image_size, image_size))\n",
        "                img_arr = keras.preprocessing.image.img_to_array(img)\n",
        "                img_arr = img_arr/255.0\n",
        "                #resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                #data.append([resized_arr, class_num])\n",
        "                data.append([img_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "        np.save('numpy_data/Large_'+label, data)\n",
        "    return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_data = save_data(small_path,'Small_',small_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIwVpeoKIvKY",
        "outputId": "e28cb7d3-bcc8-4d80-ed25-17d836ddffcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlDuc_C46S1n",
        "outputId": "948096d3-cfd0-45f1-b9ce-5588bd0205e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "large_train_data = save_data(large_train_path,'Large_Train_',large_labels)\n",
        "large_test_data = save_data(large_test_path,'Large_Test_',large_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5_aubcy6-DT",
        "outputId": "302d0b0a-6acc-4038-eee7-58d6362932a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenet_1.00_128 (Functio  (None, 4, 4, 1024)       3228864   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1024)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                13325     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,242,189\n",
            "Trainable params: 13,325\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.MobileNet(input_shape=(image_size,image_size,3), include_top=False)\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "base_model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  keras.layers.GlobalAveragePooling2D(),\n",
        "  keras.layers.Dense(13, activation='sigmoid')\n",
        "])\n",
        "\n",
        "base_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory=large_train_path, target_size=(image_size, image_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_DQeKyqNwRb",
        "outputId": "a321ae01-833c-40b9-c9d9-8601b3334c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16439 images belonging to 13 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(directory=large_test_path, target_size=(image_size, image_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps-RdzRzN2Zu",
        "outputId": "bae71fa5-30ac-48c9-98f1-d83aebf2daf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4117 images belonging to 13 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjnsD3VZ6Wl-",
        "outputId": "32f0fde7-afe8-44df-afd0-377d034e6d34"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "514/514 [==============================] - 281s 540ms/step - loss: 0.2789 - accuracy: 0.2468 - val_loss: 0.2200 - val_accuracy: 0.3245\n",
            "Epoch 2/25\n",
            "514/514 [==============================] - 270s 525ms/step - loss: 0.2114 - accuracy: 0.3627 - val_loss: 0.2055 - val_accuracy: 0.3811\n",
            "Epoch 3/25\n",
            "514/514 [==============================] - 276s 536ms/step - loss: 0.2011 - accuracy: 0.3993 - val_loss: 0.1981 - val_accuracy: 0.4088\n",
            "Epoch 4/25\n",
            "514/514 [==============================] - 271s 528ms/step - loss: 0.1952 - accuracy: 0.4224 - val_loss: 0.1936 - val_accuracy: 0.4265\n",
            "Epoch 5/25\n",
            "514/514 [==============================] - 273s 532ms/step - loss: 0.1912 - accuracy: 0.4366 - val_loss: 0.1907 - val_accuracy: 0.4336\n",
            "Epoch 6/25\n",
            "514/514 [==============================] - 272s 529ms/step - loss: 0.1882 - accuracy: 0.4482 - val_loss: 0.1882 - val_accuracy: 0.4515\n",
            "Epoch 7/25\n",
            "514/514 [==============================] - 269s 524ms/step - loss: 0.1859 - accuracy: 0.4571 - val_loss: 0.1864 - val_accuracy: 0.4530\n",
            "Epoch 8/25\n",
            "514/514 [==============================] - 265s 515ms/step - loss: 0.1837 - accuracy: 0.4667 - val_loss: 0.1851 - val_accuracy: 0.4498\n",
            "Epoch 9/25\n",
            "514/514 [==============================] - 292s 568ms/step - loss: 0.1820 - accuracy: 0.4700 - val_loss: 0.1834 - val_accuracy: 0.4647\n",
            "Epoch 10/25\n",
            "514/514 [==============================] - 265s 515ms/step - loss: 0.1805 - accuracy: 0.4784 - val_loss: 0.1823 - val_accuracy: 0.4676\n",
            "Epoch 11/25\n",
            "514/514 [==============================] - 265s 515ms/step - loss: 0.1793 - accuracy: 0.4846 - val_loss: 0.1815 - val_accuracy: 0.4710\n",
            "Epoch 12/25\n",
            "514/514 [==============================] - 265s 516ms/step - loss: 0.1781 - accuracy: 0.4879 - val_loss: 0.1805 - val_accuracy: 0.4722\n",
            "Epoch 13/25\n",
            "514/514 [==============================] - 269s 523ms/step - loss: 0.1770 - accuracy: 0.4930 - val_loss: 0.1798 - val_accuracy: 0.4749\n",
            "Epoch 14/25\n",
            "514/514 [==============================] - 273s 530ms/step - loss: 0.1760 - accuracy: 0.4961 - val_loss: 0.1793 - val_accuracy: 0.4858\n",
            "Epoch 15/25\n",
            "514/514 [==============================] - 269s 523ms/step - loss: 0.1752 - accuracy: 0.4990 - val_loss: 0.1786 - val_accuracy: 0.4831\n",
            "Epoch 16/25\n",
            "514/514 [==============================] - 269s 524ms/step - loss: 0.1744 - accuracy: 0.5020 - val_loss: 0.1784 - val_accuracy: 0.4872\n",
            "Epoch 17/25\n",
            "514/514 [==============================] - 264s 513ms/step - loss: 0.1736 - accuracy: 0.5021 - val_loss: 0.1777 - val_accuracy: 0.4875\n",
            "Epoch 18/25\n",
            "514/514 [==============================] - 265s 515ms/step - loss: 0.1729 - accuracy: 0.5062 - val_loss: 0.1773 - val_accuracy: 0.4921\n",
            "Epoch 19/25\n",
            "514/514 [==============================] - 261s 508ms/step - loss: 0.1723 - accuracy: 0.5088 - val_loss: 0.1769 - val_accuracy: 0.4923\n",
            "Epoch 20/25\n",
            "514/514 [==============================] - 261s 508ms/step - loss: 0.1717 - accuracy: 0.5118 - val_loss: 0.1764 - val_accuracy: 0.4940\n",
            "Epoch 21/25\n",
            "514/514 [==============================] - 260s 505ms/step - loss: 0.1712 - accuracy: 0.5144 - val_loss: 0.1764 - val_accuracy: 0.4904\n",
            "Epoch 22/25\n",
            "514/514 [==============================] - 259s 503ms/step - loss: 0.1707 - accuracy: 0.5138 - val_loss: 0.1761 - val_accuracy: 0.4936\n",
            "Epoch 23/25\n",
            "514/514 [==============================] - 262s 509ms/step - loss: 0.1702 - accuracy: 0.5170 - val_loss: 0.1760 - val_accuracy: 0.4987\n",
            "Epoch 24/25\n",
            "514/514 [==============================] - 264s 513ms/step - loss: 0.1697 - accuracy: 0.5169 - val_loss: 0.1756 - val_accuracy: 0.4979\n",
            "Epoch 25/25\n",
            "514/514 [==============================] - 263s 512ms/step - loss: 0.1693 - accuracy: 0.5202 - val_loss: 0.1754 - val_accuracy: 0.5001\n"
          ]
        }
      ],
      "source": [
        "epochs = 25\n",
        "\n",
        "steps_per_epoch = np.ceil(train_generator.n / batch_size)\n",
        "validation_steps = np.ceil(validation_generator.n / batch_size)\n",
        "\n",
        "history = base_model.fit_generator(generator=train_generator,\n",
        "                              steps_per_epoch = steps_per_epoch,\n",
        "                              epochs=epochs,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=validation_steps)\n",
        "\n",
        "base_model.save('MobileNet_TransferLearning_Captcha.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "captcha model",
      "provenance": [],
      "authorship_tag": "ABX9TyPn+448gyPQL8qaUEzNOXi2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}